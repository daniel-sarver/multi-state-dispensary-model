# Codex Review - Phase 3b Fixes & Population Density Analysis

**Date**: October 23, 2025
**Commit**: 4a4506a
**Status**: âœ… All Issues Resolved

---

## Codex Review Findings - All Addressed

### Issue 1: Missing Dependencies in requirements.txt âœ…

**Problem**: Phase 3 dependencies were commented out, fresh environment would fail

**Fix**:
- Uncommented: `scikit-learn>=1.3.0`, `statsmodels>=0.14.0`, `matplotlib>=3.7.0`, `seaborn>=0.12.0`, `scipy>=1.11.0`
- Added: `geopy>=2.4.0` (used in competitive_features.py)

**File**: `requirements.txt:28-33`

---

### Issue 2: Data Leakage in Cross-Validation âœ… (CRITICAL)

**Problem**: StandardScaler fitted on full training set before CV, causing data leakage
- Each CV fold's validation data influenced scaler statistics
- Artificially inflated CV RÂ² estimates

**Fix**: Implemented Pipeline for proper CV
```python
# OLD (leakage):
scaler.fit(X_train)  # Fits on ALL training data
X_train_scaled = scaler.transform(X_train)
cross_validate(model, X_train_scaled, ...)  # Validation data already saw scaler

# NEW (correct):
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # Fits separately on each CV fold
    ('ridge', Ridge(alpha=1000))
])
cross_validate(pipeline, X_train, ...)  # Each fold gets own scaler
```

**Impact**:
- CV RÂ² remains strong: **0.1872 Â± 0.0645** (still exceeds 0.15 target)
- Now truly independent estimate
- Test set evaluation improved (pipeline handles scaling internally)

**Files Modified**:
- `src/modeling/prepare_training_data.py:390-492` - Returns unscaled training data, adds `scale_test_only()` method
- `src/modeling/train_multi_state_model.py:76-157` - Implements Pipeline for Ridge training
- `src/modeling/train_multi_state_model.py:388-407` - Pipeline for LOSO validation

---

### Issue 3: Fragile State Label Extraction âœ…

**Problem**: Used `X_test['is_FL'] > 0.5` to identify FL/PA samples
- Would silently fail if FL ever exceeded ~80% of sample (scaled value drops below 0.5)
- Relied on scaled features instead of original labels

**Fix**: Extract original state labels from training_df
```python
# OLD (fragile):
fl_mask = X_test['is_FL'] > 0.5  # Breaks with class imbalance

# NEW (robust):
training_df = self.prepared_data['training_df']
test_states = training_df.loc[X_test.index, 'state']
fl_mask = test_states == 'FL'
```

**Files Modified**:
- `src/modeling/train_multi_state_model.py:299-304` - State-specific performance analysis
- `src/modeling/train_multi_state_model.py:374-381` - LOSO validation
- `src/modeling/prepare_training_data.py:466` - Added `training_df` to output dict

---

### Issue 4: Noisy Imputation of 100% Null Columns âœ…

**Problem**: Imputation loop attempted to impute 100% null columns with NaN
- Triggered "2964 NaN values remain" warning every run
- Polluted VIF analysis logs

**Fix**: Skip 100% null columns in imputation loop
```python
for feature in numeric_cols:
    missing_count = self.training_df[feature].isna().sum()

    # Skip 100% null columns (will be dropped in feature selection)
    if missing_count == len(self.training_df):
        continue
```

**File**: `src/modeling/prepare_training_data.py:107-108`

---

## Population Density Analysis - Key Findings

### Research Questions

1. **Is there a non-linear (optimal range) relationship?**
2. **Is population_density confounded by competitor counts?**

### Methodology

Created `analyze_population_density.py` with 4 tests:

1. **Correlation Analysis** - Check relationships with other features
2. **Non-Linear Test** - Compare linear vs quadratic models
3. **Confounding Test** - Model pop_density with/without competitors
4. **Binned Analysis** - Visualize relationship across density quintiles

### Results

#### 1. Correlation Analysis

| Feature | Correlation with pop_density |
|---------|------------------------------|
| pop_5mi | +0.668 (strong) |
| pop_20mi | +0.619 (strong) |
| competitors_5mi | +0.459 (moderate) |
| visits | **-0.272 (negative)** |
| saturation_5mi | -0.269 |

**Finding**: Moderate correlation with competitors (0.459), not strong enough to fully explain negative effect.

#### 2. Non-Linear Relationship Test

- **Linear Model RÂ²**: 0.0496
- **Quadratic Model RÂ²**: 0.0489 (worse!)
- **RÂ² Improvement**: -0.0006 (-1.3%)

**Finding**: âŒ **No evidence of optimal density range**. Relationship is monotonically negative (linear), not U-shaped.

#### 3. Competitor Confounding Test

| Model | RÂ² | pop_density coefficient |
|-------|-----|------------------------|
| Pop Density Only | 0.0496 | **-5,000** |
| Pop Density + Competitors | 0.1078 | **-3,681** (26% reduction) |
| Competitors Only | 0.0893 | N/A |

**Finding**: âœ… **Competitors explain only 26% of pop_density's negative effect**. 74% remains unexplained!

#### 4. Binned Analysis

| Density Bin | Avg Density | Avg Visits | Avg Competitors (5mi) |
|-------------|-------------|------------|---------------------|
| Very Low | 189 | **102,259** | 1.9 |
| Low | 967 | 72,854 | 4.2 |
| Medium | 2,055 | 62,145 | 5.6 |
| High | 3,409 | 62,247 | 7.6 |
| Very High | 6,329 | **55,616** | 8.4 |

**Finding**:
- Visits drop 46% from lowest to highest density
- Competitors increase 4.4x (1.9 â†’ 8.4)
- **But visits decline even controlling for competition!**

### Conclusions

#### Question 1: Non-Linear Relationship?

**Answer**: âŒ **No optimal range exists**

- Quadratic model performs worse than linear
- Relationship is monotonically negative (more density â†’ fewer visits)
- No evidence of "sweet spot" density range

#### Question 2: Competitor Confounding?

**Answer**: âš ï¸ **Partial - Only 26% Explained by Competition**

- Competitors reduce pop_density coefficient by 26% (-5,000 â†’ -3,681)
- But **74% of negative effect remains** even with competitors in model
- Population density has **independent negative effect** beyond competition

### Other Factors Explaining the Paradox

Since competition explains only 26%, what else causes the negative effect?

1. **Parking Constraints**
   - Dense urban cores have limited/expensive parking
   - Reduces customer accessibility vs suburban strip malls

2. **Demographic Differences**
   - Urban vs suburban customer preferences differ
   - Income, age, consumption patterns vary by density

3. **Market Saturation (Beyond Dispensaries)**
   - Dense areas have more retail competition generally
   - More entertainment/dining substitutes for discretionary spending

4. **Accessibility Issues**
   - Dense areas: traffic congestion, public transit reliance
   - Suburban areas: car-centric, easier access

5. **Regulatory Environment**
   - Zoning restrictions may differ by density tier
   - Operating hours, signage restrictions in urban cores

### Business Implications

âœ… **Suburban locations genuinely outperform dense urban cores**, independent of dispensary competition.

**Recommendations**:

1. **Prioritize suburban locations** (1,000-3,000 people/sq mi)
   - Average 62,000-72,000 visits (middle density bins)
   - Lower competition (4-6 competitors within 5mi)
   - Better parking and accessibility

2. **Avoid very high density** (>5,000 people/sq mi)
   - Average only 55,616 visits despite 6.3x more population
   - 8.4 competitors within 5mi (market saturation)
   - Parking and accessibility challenges

3. **Rural locations can work** (<500 people/sq mi)
   - Highest average visits (102,259) despite low population
   - First-mover advantage (1.9 competitors)
   - Large geographic catchment compensates for low density

4. **Focus on competition metrics** over raw population
   - `competitors_5mi` and `saturation_5mi` are better predictors than `population_density`
   - But recognize population density has independent negative effect

---

## Validation of Model Performance

### Cross-Validation (Proper Pipeline)

After fixing data leakage, model still achieves:

- **CV RÂ² = 0.1872 Â± 0.0645** âœ… (Target: 0.15)
- **2.61x improvement** over baseline (0.0716)
- Training RÂ² = 0.2371 (reasonable gap indicates good regularization)

**Conclusion**: Model performance robust even with proper CV methodology.

---

## Files Created/Modified

### Modified Files

1. **requirements.txt** - Uncommented Phase 3 dependencies
2. **src/modeling/prepare_training_data.py**
   - Returns unscaled training data for Pipeline
   - Added `scale_test_only()` method
   - Added `training_df` to output dict
   - Skip 100% null columns in imputation
3. **src/modeling/train_multi_state_model.py**
   - Implemented Pipeline for Ridge regression
   - Extract state labels from training_df
   - Pipeline for LOSO validation

### New Files

1. **src/modeling/analyze_population_density.py** (280 lines)
   - Correlation analysis
   - Non-linear relationship test
   - Competitor confounding test
   - Binned analysis with visualization

2. **data/models/validation_plots/population_density_analysis.png**
   - 4-panel visualization:
     - Scatter plot with binned means
     - Box plot by density bin
     - Competitors by density bin
     - Saturation by density bin

---

## Summary

### Codex Review: âœ… All Issues Resolved

1. âœ… Dependencies fixed
2. âœ… Data leakage eliminated via Pipeline (critical improvement)
3. âœ… State label extraction robust to class imbalance
4. âœ… Null column handling cleaned up

### Population Density: ðŸ” Mystery Partially Solved

- **26% explained by competition** (confounding)
- **74% remains independent effect** (real phenomenon)
- **No optimal range** (monotonic negative relationship)
- **Business insight validated**: Suburban > Dense Urban

### Model Status: âœ… Production Ready

- CV RÂ² = 0.1872 with proper methodology
- Pipeline prevents data leakage
- Robust state handling
- Ready for Phase 4 (Terminal Interface)

---

*Multi-State Dispensary Model - Codex Review Phase 3b*
*Date: October 23, 2025*
*Commit: 4a4506a*
*Status: âœ… Complete*
